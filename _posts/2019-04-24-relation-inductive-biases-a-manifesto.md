---
layout: post
title: "Relational Inductive Biases: a manifesto"
excerpt: DeepMind, Google Brain, MIT, and University of Edinburgh collaborators produce a manifesto on graph networks
categories: ["Deep Learning", "Graph Neural Networks (GN)"]
comments: true
---

The authors present a succinct and powerful manifesto of the importance of graph networks in artificial intelligence research. The paper is a move to synthesize the previously disjoint field of graph neural networks into a single framework: "Graph Networks (GN)".

FIGURE HERE

> We suggest that a key path forward for modern AI is to commit to combinatorial generalization as a top priority. 


# Thoughts 

> When learning, we either fit new knowledge into our existing structured representations, or adjust the structure itself to better accommodate (and make use of) the new and the old. 

My initial reading of this yielded the natural extension that we should be applying reinforcement learning to structured representation. 

FIGURE SHOWING GN, DRN, ETC

@misc{battaglia2018relational,
    title={Relational inductive biases, deep learning, and graph networks},
    author={Peter W. Battaglia and Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu},
    year={2018},
    eprint={1806.01261},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

