<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Software Sharing in Medical Research | Matt's Log</title><meta name=keywords content><meta name=description content="I was reading Mohammed AlQuraishi's [post][1] &#34;AlphaFold @ CASP13: What just happened?&#34; recently about DeepMind's advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images."><meta name=author content="Matt Goodman"><link rel=canonical href=https://goodmattg.github.io/posts/software-sharing-in-medical-research/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ec8da366ca2fb647537ccb7a8f6fa5b4e9cd3c7a0d3171dd2d3baad1e49c8bfc.css integrity="sha256-7I2jZsovtkdTfMt6j2+ltOnNPHoNMXHdLTuq0eSci/w=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://goodmattg.github.io/magnet.ico><link rel=icon type=image/png sizes=16x16 href=https://goodmattg.github.io/magnet-16x16.ico><link rel=icon type=image/png sizes=32x32 href=https://goodmattg.github.io/magnet-32x32.ico><link rel=apple-touch-icon href=https://goodmattg.github.io/magnet-apple-touch-icon.png><link rel=mask-icon href=https://goodmattg.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Software Sharing in Medical Research"><meta property="og:description" content="I was reading Mohammed AlQuraishi's [post][1] &#34;AlphaFold @ CASP13: What just happened?&#34; recently about DeepMind's advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images."><meta property="og:type" content="article"><meta property="og:url" content="https://goodmattg.github.io/posts/software-sharing-in-medical-research/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-09-09T00:00:00+00:00"><meta property="article:modified_time" content="2018-09-09T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Software Sharing in Medical Research"><meta name=twitter:description content="I was reading Mohammed AlQuraishi's [post][1] &#34;AlphaFold @ CASP13: What just happened?&#34; recently about DeepMind's advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://goodmattg.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Software Sharing in Medical Research","item":"https://goodmattg.github.io/posts/software-sharing-in-medical-research/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Software Sharing in Medical Research","name":"Software Sharing in Medical Research","description":"I was reading Mohammed AlQuraishi's [post][1] \"AlphaFold @ CASP13: What just happened?\" recently about DeepMind's advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images.","keywords":[],"articleBody":" I was reading Mohammed AlQuraishi’s post1 “AlphaFold @ CASP13: What just happened?” recently about DeepMind’s advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images. To put it bluntly, it isn’t helpful that I can quickly find ten good papers claiming state-of-the-art performance on tumor segmentation if I can’t quickly download and verify the model performance on a non-toy dataset. In my view, a toy dataset is a dataset that doesn’t reflect the enumerable subtleties of real-world data. I.e. a dataset filtered to remove weird edge-cases, complex low probability situations, and messy inputs. As an aside, modern tumor ultrasound datasets are laughably perfect. They are all ~100 samples of perfectly cropped tumors with contiguous inner regions and no artefacts that would reflect rare conditions a radiologist would be trained to identify.\nAs I discussed earlier, it is clear that between the Xu and Zhang groups enough was known to develop a system that would have perhaps rivaled AlphaFold. But because of the siloed nature of the field, it only gets a “gradient update” once every two years. Academic groups are thus forced to independently rediscover the wheel over and over. In DeepMind’s case, even though the team was small in comparison to the total headcount wof academic groups, they were presumably able to share information on a very regular basis, and this surely contributed to their success.\nI can relate. There is a recent paper from a major medical research center that claims best-in-class performance on the tumor segmentation problem. A cursory reading yields that the best-in-class performance is probably legitimate and would extend well to my current work. The code is not publicly available and the research team immediately rejected my request to collaborate. In all fairness, I don’t know why they are hesitant to collaborate; there could be IP concerns related to grant providers, or it could be a plain desire to maintain competitive advantage. My place is not to ask why, but this does put my work in a tough position.\nI am building a complex system consisting of multiple sub-components for my current work. These components include but are not limited to: frame OCR, frame scale normalization, tumor segmentation, tumor diagnosis, etc. For the final product to exceed expectations, every component needs to operate with extremely high performance. So while I know there’s a universe of segmentation algorithms out there, one of which probably does have amazing performance invariant to the heterogeneity of lesion interior, I can’t slot in any of these systems without re-implementing them myself, and I can’t rigorously determine which system to slot in because that would require verification on our real-world dataset. So I’m suddenly forced to make decisions about time to payoff, ease of implementation, and verifiability of a crude implementation. I ended up going with a brute-force style approach simply because it’s the only thing that I could both quickly implement myself and verify correctness.\nYou would think by now that these building blocks would be readily available within the research community, but they aren’t. It’s a self-enforced barrier to entry that we should work hard to tear down. It is also worth noting that DeepMind2 is looking into the mammography problem as well.\nhttps://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/ ↩︎\nhttps://deepmind.com/blog/applying-machine-learning-mammography/ ↩︎\n","wordCount":"555","inLanguage":"en","datePublished":"2018-09-09T00:00:00Z","dateModified":"2018-09-09T00:00:00Z","author":{"@type":"Person","name":"Matt Goodman"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://goodmattg.github.io/posts/software-sharing-in-medical-research/"},"publisher":{"@type":"Organization","name":"Matt's Log","logo":{"@type":"ImageObject","url":"https://goodmattg.github.io/magnet.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://goodmattg.github.io accesskey=h title="Matt's Log (Alt + H)">Matt's Log</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://goodmattg.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=https://goodmattg.github.io/about title=About><span>About</span></a></li><li><a href=https://goodmattg.github.io/bookshelf title=Bookshelf><span>Bookshelf</span></a></li><li><a href=https://goodmattg.github.io/quotes title=Quotes><span>Quotes</span></a></li><li><a href=https://goodmattg.github.io/contact title=Contact><span>Contact</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Software Sharing in Medical Research</h1><div class=post-description>I was reading Mohammed AlQuraishi's [post][1] "AlphaFold @ CASP13: What just happened?" recently about DeepMind's advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images.</div><div class=post-meta><span title='2018-09-09 00:00:00 +0000 UTC'>September 9, 2018</span>&nbsp;·&nbsp;Matt Goodman</div></header><div class=post-content><hr><p>I was reading Mohammed AlQuraishi&rsquo;s post<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> &ldquo;AlphaFold @ CASP13: What just happened?&rdquo; recently about DeepMind&rsquo;s advance in protein folding. His point about research siloing holding the whole field back resonated with me in light of my current work identifying malignant tumors in ultrasound images. To put it bluntly, it isn&rsquo;t helpful that I can quickly find ten good papers claiming state-of-the-art performance on tumor segmentation if I can&rsquo;t quickly download and verify the model performance on a non-toy dataset. In my view, a toy dataset is a dataset that doesn&rsquo;t reflect the enumerable subtleties of real-world data. I.e. a dataset filtered to remove weird edge-cases, complex low probability situations, and messy inputs. As an aside, modern tumor ultrasound datasets are laughably perfect. They are all ~100 samples of perfectly cropped tumors with contiguous inner regions and no artefacts that would reflect rare conditions a radiologist would be trained to identify.</p><blockquote><p>As I discussed earlier, it is clear that between the Xu and Zhang groups enough was known to develop a system that would have perhaps rivaled AlphaFold. But because of the siloed nature of the field, it only gets a “gradient update” once every two years. Academic groups are thus forced to independently rediscover the wheel over and over. In DeepMind’s case, even though the team was small in comparison to the total headcount wof academic groups, they were presumably able to share information on a very regular basis, and this surely contributed to their success.</p></blockquote><p>I can relate. There is a recent paper from a major medical research center that claims best-in-class performance on the tumor segmentation problem. A cursory reading yields that the best-in-class performance is probably legitimate and would extend well to my current work. The code is not publicly available and the research team immediately rejected my request to collaborate. In all fairness, I don&rsquo;t know why they are hesitant to collaborate; there could be IP concerns related to grant providers, or it could be a plain desire to maintain competitive advantage. My place is not to ask why, but this does put my work in a tough position.</p><p>I am building a complex system consisting of multiple sub-components for my current work. These components include but are not limited to: frame OCR, frame scale normalization, tumor segmentation, tumor diagnosis, etc. For the final product to exceed expectations, every component needs to operate with extremely high performance. So while I know there&rsquo;s a universe of segmentation algorithms out there, one of which probably <em>does</em> have amazing performance invariant to the heterogeneity of lesion interior, I can&rsquo;t slot in any of these systems without re-implementing them myself, and I can&rsquo;t rigorously determine which system to slot in because that would require verification on our real-world dataset. So I&rsquo;m suddenly forced to make decisions about time to payoff, ease of implementation, and verifiability of a crude implementation. I ended up going with a brute-force style approach simply because it&rsquo;s the only thing that I could both quickly implement myself and verify correctness.</p><p>You would think by now that these building blocks would be readily available within the research community, but they aren&rsquo;t. It&rsquo;s a self-enforced barrier to entry that we should work hard to tear down. It is also worth noting that DeepMind<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> is looking into the mammography problem as well.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/>https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://deepmind.com/blog/applying-machine-learning-mammography/>https://deepmind.com/blog/applying-machine-learning-mammography/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://goodmattg.github.io>Matt's Log</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>